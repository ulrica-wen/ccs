import streamlit as st
from PIL import Image
import os
dir_path = os.path.split(os.path.realpath(__file__))[0]
import sys
sys.path.append(dir_path)

st.set_page_config(
    page_title="éŸ³ç»¼æˆ˜ç»©",
    page_icon=":Scroll:",
    layout='wide'
)

st.title('ğŸ‰ éŸ³ç»¼æˆ˜ç»©')

st.subheader('Introduction')
st.markdown(
    """
    DeepFloyd IF is a state-of-the-art text-to-image model released by StabilityAI in late April, 2023 that achieves a high degree of photorealism and language understanding. DeepFloyd is built with multiple neural modules (independent neural networks that tackle specific tasks), and generates high-resolution images in a cascading approach. The model is composed of a frozen text encoder and three cascaded pixel diffusion modules: a base model that generates 64x64 pixel image based on the input text prompt and two super-resolution models that generates images with resolution 256x256 pixel and 1024x1024 pixel. All stages of the model utilize a frozen text encoder based on the T5-XXL to extract text embeddings, which are then fed into a UNet architecture enhanced with cross-attention and attention pooling. 
    \n
    As a result, DeepFloyd achieves a zero-shot Frechet Inception Distance (FID) score of 6.66 on the COCO dataset, which outperforms other novel text-to-image models including DALL-E 2 (10.39), Imagen (7.27), and eDiff-I (6.95).

    **The following generation flowchart demonstrates the three-stage process**:
    \n

    - A **text prompt** is passed through the frozen T5-XXL language model to convert into a qualitative text representation
    \n
    - **Stage 1**: A base diffusion model transforms the qualitative text into a 64x64 image. There are three versions of the base model each with different number of parameters: 400M, 900M, and 4.3B. 
    \n
    - **Stage 2**: To upscale the image, two text-conditional super-resolution models are applied to the output of the base model. The first super-resolution model upscales the 64x64 image to 256x256. 
    \n
    - **Stage 3**: The second super-resolution diffusion model is applied and produces a 1024x1024 image.
    """
)

tab1, tab2, tab3, tab4 = st.tabs(["æŠ«è†æ–©æ£˜3", "å£°ç”Ÿä¸æ¯å®¶å¹´å", "å¤©èµçš„å£°éŸ³5","ä¸€èµ·æ¥çœ‹æˆ‘ä»¬çš„æ¼”å”±ä¼š"])



with tab1:
   st.header("æŠ«è†æ–©æ£˜æˆå›¢å“¥å“¥å¹³å°æ•°æ®æ±‡æ€»")
   st.image('/Users/wcheng/Desktop/ticket/é™ˆæ¥šç”Ÿ/ccs/image/æ‰¹å“¥æ±‡æ€».jpg', width=1000)
   with st.expander("æŸ¥çœ‹å…·ä½“æ•°æ®"):
        st.image('/Users/wcheng/Desktop/ticket/é™ˆæ¥šç”Ÿ/ccs/image/æ‰¹å“¥_æˆ˜ç»©1.jpg', width=800)
        st.image('/Users/wcheng/Desktop/ticket/é™ˆæ¥šç”Ÿ/ccs/image/æ‰¹å“¥_æˆ˜ç»©2.jpg', width=800)
        st.image('/Users/wcheng/Desktop/ticket/é™ˆæ¥šç”Ÿ/ccs/image/æ‰¹å“¥_æˆ˜ç»©3.jpg', width=800)
        st.image('/Users/wcheng/Desktop/ticket/é™ˆæ¥šç”Ÿ/ccs/image/æ‰¹å“¥_æˆ˜ç»©4.jpg', width=800)
        st.write("""
            ä¸Šé¢çš„å›¾è¡¨å±•ç¤ºäº†æˆ‘ä¸ºæ‚¨é€‰æ‹©çš„ä¸€äº›æ•°å­—ã€‚
            è¿™äº›æ•°å­—æ˜¯é€šè¿‡çœŸå®çš„éª°å­æ‘‡å‡ºæ¥çš„ï¼Œæ‰€ä»¥å®ƒä»¬*ä¿è¯*æ˜¯éšæœºçš„ã€‚
        """)

with tab2:
   st.header("A dog")
   st.image("/Users/wcheng/Desktop/ticket/é™ˆæ¥šç”Ÿ/ccs/image/æ‰¹å“¥_æˆ˜ç»©1.jpg", width=200)

with tab3:
   st.header("An owl")
   st.image("/Users/wcheng/Desktop/ticket/é™ˆæ¥šç”Ÿ/ccs/image/æ‰¹å“¥_æˆ˜ç»©1.jpg", width=200)
